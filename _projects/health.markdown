---
layout: page
title: Voice analytics for healthcare
description: Detecting upper respiratory tract illness through patients voice
img: /assets/img/covid19screening.jpg
importance: 1
category: audio
---
Voice analytics for healthcare is an evolving research direction where the aim is to process the continuous acoustic signal and generate insights about the patient’s conditions. Traditionally, speech technology in the healthcare industry has been utilised for transcribing patient notes for doctors, detect patient emotion, and improving the doctor-patient experience. There is also an emerging direction of speech technology for healthcare where the aim is to assist doctors in medical diagnosis. The assistance can be in the form of diagnosis prediction or symptom detection.

The ability of speech technology to predict medical conditions is continuously being improved over the past decade in different directions. The recent work by:
- [Emily Provost](https://web.eecs.umich.edu/~emilykmp/) ([CHAI lab](https://web.eecs.umich.edu/~emilykmp/chai/index.html)) in assistive technology for bipolar disorder, aphasia, Huntington disease, suicide risk
- [Najim Dehak](https://engineering.jhu.edu/ece/faculty/najim-dehak/) and [Laureano Moro-Velázquez](https://pages.jh.edu/lmorove1/index.html) in early Parkinson's disease detection
 - [Abeer Alwan](https://www.ee.ucla.edu/abeer-alwan/) ([SPAPL lab](http://www.seas.ucla.edu/spapl/index.html)) in analysis of disfluency in children's speech

The COVID-19 pandemic starting in 2019 has resulted in more than 100 million infections, and more than 2 million casualties. The global crisis spans over 200 countries. One of the ways to slow the exponential growth down is early detection of COVID-19 infection in a patient followed by quick isolation. The traditional testing methods are expensive, takes 3-5 days to get results and are insufficient in number. This motivates transfering speech technology for the detection of symtoms of such disease. 

#### <i> Can we non-invasively characterize and detect COVID-19 from voice? </i>

Trying to answer this question has the potential to enable rapid and scalable testing, reducing its prevalence and saving lives. 

Voiced sounds are produced through the process of phonation, where the movement of vocal folds are self-sustained through the interaction of physical and aerodynamic forces across the glottis. The actual movements are governed by various biomechanical properties of the vocal fold such as elasticity, resistance, Young’s modulus, viscosity etc. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/vocalfold.png' | relative_url }}" alt="" title="example image"/>
    </div>
</div>
<div class="caption">
    Laryngoscopic view of the vocal folds
</div>

This vocal fold motion and voice production can be simulated by physics models with assumptions. This discrepany surfaces up in glottal flow waveform generated by a physical model of healthy person (1d asymmetrical body mass model) vs actual glottal waveform obtained. So by capturing the vocal fold oscillation impairment as discrepancy surfacing in the form of differences between glottal flow waveform obtained from inverse filtering and glottal flow waveform estimated from 1d asymmetrical body mass model, can provide the required insight about upper respiratory track diseases.

#### ADLES (adjoint least square estimation method)

$$ \min \int_{0}^{T} (u_0(t) - u_0^m(t))^2 dt $$

$$ \min \int_{0}^{T} (\tilde{c}d(2x_0 + x_l(t) + x_r(t)) - \frac{A(0)}{\rho c}\mathcal{F}^{-1}(p_m(t)))^2$$

$$ \mathrm{s.t.}\quad \ddot{x}_r + \beta (1 + x_r^2)\dot{x}_r + x_r - \frac{\Delta}{2}x_r = \alpha (\dot{x}_r + \dot{x}_l)$$

$$ \ddot{x}_l + \beta (1 + x_l^2)\dot{x}_l + x_l + \frac{\Delta}{2}x_l = \alpha (\dot{x}_r + \dot{x}_l) $$

$$ x_r(0) = C_r, x_l(0) = C_l $$

$$ \dot{x}_r(0) = 0, \dot{x}_l(0) = 0 $$


We use ADLES algorithm to iteratively estimate the model parameters $$\alpha$$, $$\beta$$, $$\Delta$$. This is achieved by minimizing the error between the glottal flow waveform obtained by inverse filtering, and the vocal fold oscillations predicted by the model as its parameter space is sampled.

The phasor plots obtained are shown below:
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/male_negative.png' | relative_url }}" alt="" title="example image"/>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/male_positive.png' | relative_url }}" alt="" title="example image"/>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/female_negative_3.png' | relative_url }}" alt="" title="example image"/>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/female_positive.png' | relative_url }}" alt="" title="example image"/>
    </div>
</div>
<div class="caption">
    The second and fourth plots are phase space trajectories for male and female symptomatic COVID-19 patients for the vowel /i/. While the first and third plots are phase space trajectories for male and female healthy patients for the vowel /i/. In each plot, the left panel corresponds to left vocal fold displacement (x-axis) vs. left vocal fold velocity (y-axis) and right panel corresponds to right vocal fold displacement (x-axis) vs. right vocal fold velocity (y-axis)
</div>

This approach provides a physics motivated approach to distinguish upper respiratory tract illness symtomatic patients. 

There has been recent development in COVID-19 detection with [DiCOVA Challenge](https://dicova2021.github.io/) at INTERSPEECH 2021. This has lead to deep learning based methods being introduced as well.

## References
[1] M. Al Ismail, S. Deshmukh and R. Singh, "Detection of Covid-19 Through the Analysis of Vocal Fold Oscillations," ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 1035-1039, doi: 10.1109/ICASSP39728.2021.9414201

[2] S. Deshmukh, M. Al Ismail and R. Singh, "Interpreting Glottal Flow Dynamics for Detecting Covid-19 From Voice," ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 1055-1059, doi: 10.1109/ICASSP39728.2021.9414530